{
  "metadata": {
    "name": "Regression",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### To Import Spark SQL and Spark ML Libraries \nTo Import Spark SQL and Spark ML Libraries. It is neccessary to access the functions."
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.types import *\nfrom pyspark.ml.regression import LinearRegression , DecisionTreeRegressor, RandomForestRegressor, GBTRegressionModel, GBTRegressor, FMRegressor\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import *\nfrom pyspark.ml import *\nfrom pyspark.ml.classification import *\nfrom pyspark.ml.evaluation import *\nfrom pyspark.mllib.evaluation import *\nfrom pyspark.sql.types import *\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### To run the code in PySpark CLI\n\nSet the following to True:\n\nPYSPARK_CLI \u003d True"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nIS_DB \u003d True # Run the code in Databricks\n\nPYSPARK_CLI \u003d False\nif PYSPARK_CLI:\n    sc \u003d SparkContext.getOrCreate()\n    spark \u003d SparkSession(sc)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\neCommerceSchema \u003d StructType([\n  StructField(\"event_time\", TimestampType(), False),\n  StructField(\"event_type\", StringType(), False),\n  StructField(\"product_id\", IntegerType(), False),\n  StructField(\"category_id\", LongType(), False),\n  StructField(\"StringType\", StringType(), False),\n  StructField(\"brand\", StringType(), False),\n  StructField(\"price\", DoubleType(), False),\n  StructField(\"user_id\", IntegerType(), False),\n  StructField(\"user_session\", StringType(), False),\n])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##Load Source Data\nThe data for this exercise is provided as a CSV file containing details of e-commerce items and catetegories. The data includes specific characteristics (or features) for each item, as well as a label column indicating what is the price of each item.\n\nYou will load this data into a DataFrame and display it."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Read the csv file from HDFS (Hadoop File System)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# File location and type\nfile_location \u003d \"/user/apandey9/5560/2019-Oct_Master.csv\"\nfile_type \u003d \"csv\"\n\n# CSV options\ninfer_schema \u003d \"true\"\nfirst_row_is_header \u003d \"true\"\ndelimiter \u003d \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf \u003d spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location) \n\ndf \u003d df.withColumnRenamed(\u0027# File format is event_time\u0027, \u0027event_time\u0027)\ndf \u003d df.filter((col(\"brand\") !\u003d \"No value\") \u0026 (col(\"category_code\") !\u003d \"No value\"))\n\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Converting the string type columns into integer using withColumn"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d df.withColumn(\"event_type\", when(df.event_type \u003d\u003d \u0027view\u0027, 1) \\\n                  .when(df.event_type \u003d\u003d \u0027cart\u0027, 2) \\\n                  .when(df.event_type \u003d\u003d \u0027purchase\u0027, 3))\n\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Converting the string type columns into indices using StringIndexer\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.feature import StringIndexer\n\nindexer \u003d StringIndexer(inputCol\u003d\"brand\", outputCol\u003d\"brandIndex\")\nindexer1 \u003d StringIndexer(inputCol\u003d\"category_code\", outputCol\u003d\"category_codeIndex\")\ndf \u003d indexer.fit(df).transform(df) \ndf \u003d indexer1.fit(df).transform(df)\ndf.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Create a temporary view of the dataframe \"df\"\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Create a view or table\ntemp_table_name \u003d \"2019_Oct_Master_csv\"\ndf.createOrReplaceTempView(temp_table_name)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nif PYSPARK_CLI:\n    csv \u003d spark.read.csv(\u00272019_Oct_Master_csv\u0027, inferSchema\u003dTrue, header\u003dTrue)\nelse:\n    csv \u003d spark.sql(\"SELECT * FROM 2019_Oct_Master_csv\")\n\n\ncsv.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Selecting features\nIn this following step, we are selecting the features that are useful for Event_Type Prediction."
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata \u003d csv.select(\"product_id\", \"brandIndex\", \"category_codeIndex\", \"event_type\", \"user_id\", col(\"price\").alias(\"label\"))\ndata.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Split the Data\nIt is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, you will use 70% of the data for training, and reserve 30% for testing."
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Split the data\nsplits \u003d data.randomSplit([0.7, 0.3])\ntrain \u003d splits[0]\ntest \u003d splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n\nprint (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## RANDOM FOREST REGRESSION\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Prepare the Training Data\nTo train the regression model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nassembler_rf \u003d VectorAssembler(inputCols\u003d[\"product_id\", \"brandIndex\", \"category_codeIndex\", \"event_type\" , \"user_id\" ], outputCol\u003d\"features\")\n\n#lr \u003d LinearRegression(labelCol\u003d\"label\", featuresCol\u003d\"normFeatures\")\nrf \u003d RandomForestRegressor(labelCol\u003d\"label\", featuresCol\u003d\"features\", maxBins\u003d3000)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Parameter Building and Train using Train split Validator\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nparamGrid_rf \u003d ParamGridBuilder() \\\n  .addGrid(rf.maxDepth, [2, 3]) \\\n  .addGrid(rf.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Train Validation Split that creates a feature vector and trains a Random Forest model"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline0_rf \u003d Pipeline(stages\u003d[assembler_rf, rf])\n\ntvs_rf \u003d TrainValidationSplit(estimator\u003dpipeline0_rf, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGrid_rf, trainRatio\u003d0.8)\n\nmodel0_rf \u003d tvs_rf.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Test the Model\r\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price."
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction0_rf \u003d model0_rf.transform(test)\npredicted0_rf \u003d prediction0_rf.select(\"features\", \"prediction\", \"trueLabel\")\npredicted0_rf.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Calculate TrainValidationSplit RMSE and R2\r\nWe will now calculate RMSE and R2 for Random Forest Regression using Train Split Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values."
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator0_rf \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_rf_0 \u003d evaluator0_rf.evaluate(predicted0_rf)\n\n#Determining Evaluator RMSE\nevaluator0_rf \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_rf_0 \u003d evaluator0_rf.evaluate(predicted0_rf)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_rf_0)\nprint (\"Co-efficient of Determination (r2)\", r2_rf_0)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Parameter Building and Train using Cross Validator\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# TODO: params refered to the reference above\nparamGridCV_rf \u003d ParamGridBuilder() \\\n  .addGrid(rf.maxDepth, [3, 5]) \\\n  .addGrid(rf.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Cross validator that creates a feature vector and trains a Random Forest model"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline1_rf \u003d Pipeline(stages\u003d[assembler_rf, rf])\n\n# TODO: K \u003d 3\n# K\u003d3, 5\nK \u003d 3\ncv_rf \u003d CrossValidator(estimator\u003dpipeline1_rf, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGridCV_rf, numFolds \u003d K)\n\n# the third best model\nmodel1_rf \u003d cv_rf.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Test the Model\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction1_rf \u003d model1_rf.transform(test)\npredicted1_rf \u003d prediction1_rf.select(\"features\", \"prediction\", \"trueLabel\")\npredicted1_rf.show(20)"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator1_rf \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_rf_1 \u003d evaluator1_rf.evaluate(predicted1_rf)\n\n#Determining Evaluator RMSE\nevaluator1_rf \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_rf_1 \u003d evaluator1_rf.evaluate(predicted1_rf)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_rf_1)\nprint (\"Co-efficient of Determination (r2)\", r2_rf_1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n## GRADIENT BOOST TREE REGRESSION"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "%md\n### Prepare the Training Data\nTo train the regression model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector."
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nassembler_gbt \u003d VectorAssembler(inputCols \u003d [\"product_id\", \"brandIndex\", \"category_codeIndex\", \"event_type\" , \"user_id\"], outputCol\u003d\"features\")\n\n#gbt \u003d GBTRegression(labelCol\u003d\"label\", featuresCol\u003d\"normFeatures\")\ngbt \u003d GBTRegressor(labelCol\u003d\"label\", featuresCol\u003d\"features\", maxBins\u003d3000)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Parameter Building and Train using Train split Validator"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nparamGrid_gbt \u003d ParamGridBuilder() \\\n  .addGrid(gbt.maxDepth, [2, 3]) \\\n  .addGrid(gbt.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# This model was to run for Features Importance\n#pipeline0_gbt \u003d Pipeline(stages\u003d[assembler_gbt, gbt])"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#model \u003d pipeline0_gbt.fit(train)"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#rfModel \u003d model.stages[-1]\n#print(rfModel.toDebugString)"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# This code is used for feature engineering. \n\n#featureImp \u003d pd.DataFrame(list(zip(assembler_gbt.getInputCols(),\n#rfModel.featureImportances)),\n#columns\u003d[\"feature\", \"importance\"])\n#featureImp.sort_values(by\u003d\"importance\", ascending\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Building the Pipeline\nDefine a pipeline for Train Validation Split that creates a feature vector and trains a GRADIENT BOOST TREE model"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ntvs_gbt \u003d TrainValidationSplit(estimator\u003dpipeline0_gbt, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGrid_gbt, trainRatio\u003d0.8)\n\nmodel0_gbt \u003d tvs_gbt.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Test the Model\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction0_gbt \u003d model0_gbt.transform(test)\npredicted0_gbt \u003d prediction0_gbt.select(\"features\", \"prediction\", \"trueLabel\")\npredicted0_gbt.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Calculate CrossValidator RMSE and R2\nWe will now calculate RMSE and R2 for GBT Regression using Train Split Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator0_gbt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_gbt_0 \u003d evaluator0_gbt.evaluate(predicted0_gbt)\n\n#Determining Evaluator RMSE\nevaluator0_gbt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_gbt_0 \u003d evaluator0_gbt.evaluate(predicted0_gbt)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_gbt_0)\nprint (\"Co-efficient of Determination (r2)\", r2_gbt_0)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Parameter Building and Train using Cross Validator\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# TODO: params refered to the reference above\nparamGridCV_gbt \u003d ParamGridBuilder() \\\n  .addGrid(gbt.maxDepth, [3, 5]) \\\n  .addGrid(gbt.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Cross Validator that creates a feature vector and trains a GRADIENT BOOST TREE model"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline1_gbt \u003d Pipeline(stages\u003d[assembler_gbt, gbt])\nK \u003d 3\ncv_gbt \u003d CrossValidator(estimator\u003dpipeline1_gbt, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGridCV_gbt, numFolds \u003d K)\n\nmodel1_gbt \u003d cv_gbt.fit(train)"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Test the Model\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction1_gbt \u003d model1_gbt.transform(test)\npredicted1_gbt \u003d prediction1_gbt.select(\"features\", \"prediction\", \"trueLabel\")\npredicted1_gbt.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Calculate CrossValidator RMSE and R2\nWe will now calculate RMSE and R2 for GBT Regression using Cross Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator1_gbt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_gbt_1 \u003d evaluator1_gbt.evaluate(predicted1_gbt)\n\n#Determining Evaluator RMSE\nevaluator1_gbt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_gbt_1 \u003d evaluator1_gbt.evaluate(predicted1_gbt)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_gbt_1)\nprint (\"Co-efficient of Determination (r2)\", r2_gbt_1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n## DECISION TREE REGRESSION"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Prepare the Training Data\r\nTo train the regression model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector."
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nassembler_dt \u003d VectorAssembler(inputCols \u003d [\"product_id\", \"brandIndex\", \"category_codeIndex\", \"event_type\" , \"user_id\"], outputCol\u003d\"features\")\n\n#gbt \u003d GBTRegression(labelCol\u003d\"label\", featuresCol\u003d\"normFeatures\")\ndt \u003d DecisionTreeRegressor(labelCol\u003d\"label\", featuresCol\u003d\"features\", maxBins\u003d3000)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Parameter Building and Train using Train split Validator"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nparamGrid_dt \u003d ParamGridBuilder() \\\n  .addGrid(dt.maxDepth, [2, 3]) \\\n  .addGrid(dt.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Train Validation Split that creates a feature vector and trains a Decision TREE model"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline0_dt \u003d Pipeline(stages\u003d[assembler_dt, dt])\n\ntvs_dt \u003d TrainValidationSplit(estimator\u003dpipeline0_dt, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGrid_dt, trainRatio\u003d0.8)\n\nmodel0_dt \u003d tvs_dt.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Test the Model\r\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price."
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction0_dt \u003d model0_dt.transform(test)\npredicted0_dt \u003d prediction0_dt.select(\"features\", \"prediction\", \"trueLabel\")\npredicted0_dt.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Calculate TrainValidationSplit RMSE and R2\r\nWe will now calculate RMSE and R2 for Decision Tree Regression using Train Split Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values."
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator0_dt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_dt_0 \u003d evaluator0_dt.evaluate(predicted0_dt)\n\n#Determining Evaluator RMSE\nevaluator0_dt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_dt_0 \u003d evaluator0_dt.evaluate(predicted0_dt)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_dt_0)\nprint (\"Co-efficient of Determination (r2)\", r2_dt_0)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Parameter Building and Train using Cross Validator"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# TODO: params refered to the reference above\nparamGridCV_dt \u003d ParamGridBuilder() \\\n  .addGrid(dt.maxDepth, [3, 5]) \\\n  .addGrid(dt.minInfoGain, [0.0]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Cross Validator that creates a feature vector and trains a Decision TREE model"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline1_dt \u003d Pipeline(stages\u003d[assembler_dt, dt])\nK \u003d 3\ncv_dt \u003d CrossValidator(estimator\u003dpipeline1_dt, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGridCV_dt, numFolds \u003d K)\n\nmodel1_dt \u003d cv_dt.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Test the Model\r\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price."
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction1_dt \u003d model1_dt.transform(test)\npredicted1_dt \u003d prediction1_dt.select(\"features\", \"prediction\", \"trueLabel\")\npredicted1_dt.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Calculate TrainValidationSplit RMSE and R2\nWe will now calculate RMSE and R2 for Decision Tree Regression using Cross Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator1_dt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_dt_1 \u003d evaluator1_dt.evaluate(predicted1_dt)\n\n#Determining Evaluator RMSE\nevaluator1_dt \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_dt_1 \u003d evaluator1_dt.evaluate(predicted1_dt)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_dt_1)\nprint (\"Co-efficient of Determination (r2)\", r2_dt_1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n## LINEAR REGRESSION"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Prepare the Training Data\r\nTo train the regression model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector."
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nassembler_lr \u003d VectorAssembler(inputCols \u003d [\"product_id\", \"brandIndex\", \"category_codeIndex\", \"event_type\" , \"user_id\"], outputCol\u003d\"features\")\n\n#gbt \u003d GBTRegression(labelCol\u003d\"label\", featuresCol\u003d\"normFeatures\")\nlr \u003d LinearRegression(labelCol\u003d\"label\", featuresCol\u003d\"features\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Parameter Building and Train using Train split Validator\n"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nparamGrid_lr \u003d ParamGridBuilder() \\\n  .addGrid(lr.maxIter, [10]) \\\n  .addGrid(lr.regParam, [0.3]) \\\n  .build()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Building the Pipeline\nDefine a pipeline for Train Validation Split that creates a feature vector and trains a Linear Regression model"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline_tvs_lr \u003d Pipeline(stages\u003d[assembler_lr , lr])\n\ntvs_lr \u003d TrainValidationSplit(estimator\u003dpipeline_tvs_lr, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGrid_lr, trainRatio\u003d0.8)\n\nmodel0_tvs_lr \u003d tvs_lr.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Test the Model\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction0_lr \u003d model0_tvs_lr.transform(test)\npredicted0_lr \u003d prediction0_lr.select(\"features\", \"prediction\", \"trueLabel\")\npredicted0_lr.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Calculate TrainValidationSplit RMSE and R2\nWe will now calculate RMSE and R2 for Linear Regression using Train Split Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator0_lr \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_lr_0 \u003d evaluator0_lr.evaluate(predicted0_lr)\n\n#Determining Evaluator RMSE\nevaluator0_lr \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_lr_0 \u003d evaluator0_lr.evaluate(predicted0_lr)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_lr_0)\nprint (\"Co-efficient of Determination (r2)\", r2_lr_0)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Parameter Building and Train using Cross Validator"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# TODO: params refered to the reference above\nparamGridCV_lr \u003d ParamGridBuilder() \\\n  .addGrid(lr.maxIter, [20]) \\\n  .addGrid(lr.regParam, [0.5]) \\\n  .build()"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%md\n### Building the Pipeline\nDefine a pipeline for Cross Validator that creates a feature vector and trains a Linear Regression model"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npipeline1_lr \u003d Pipeline(stages\u003d[assembler_lr, lr])\nK \u003d 3\ncv_lr \u003d CrossValidator(estimator\u003dpipeline1_lr, evaluator\u003dRegressionEvaluator(), estimatorParamMaps\u003dparamGridCV_lr, numFolds \u003d K)\n\nmodel1_lr \u003d cv_lr.fit(train)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Test the Model\nNow you\u0027re ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict Item Price where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted Item Price to the actual Item Price.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprediction1_lr \u003d model1_lr.transform(test)\npredicted1_lr \u003d prediction1_lr.select(\"features\", \"prediction\", \"trueLabel\")\npredicted1_lr.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n### Calculate CrossValidator RMSE and R2\r\nWe will now calculate RMSE and R2 for Linear Regression using Cross Validator. There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual Item Price Values."
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Determining Evaluator RMSE\nevaluator1_lr \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse_lr_1 \u003d evaluator1_lr.evaluate(predicted1_lr)\n\n#Determining Evaluator RMSE\nevaluator1_lr \u003d RegressionEvaluator(labelCol\u003d\"trueLabel\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nr2_lr_1 \u003d evaluator1_lr.evaluate(predicted1_lr)\n\n\nprint (\"Root Mean Square Error (RMSE)\", rmse_lr_1)\nprint (\"Co-efficient of Determination (r2)\", r2_lr_1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n###References\r\nhttps://spark.apache.org/docs/latest/ml-classification-regression.html#regression\r\n\r\nhttps://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.evaluation.RegressionMetrics.html\r\n\r\nhttps://spark.apache.org/docs/1.5.2/ml-ensembles.html"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    }
  ]
}